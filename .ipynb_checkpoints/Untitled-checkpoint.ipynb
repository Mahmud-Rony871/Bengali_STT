{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd064cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import librosa\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "# Set seed for experiment reproducibility\n",
    "seed = 777\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa0c4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_target_len=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe249f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
    "        super().__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid,trainable=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        x = self.emb(x)\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "class SpeechFeatureEmbedding(layers.Layer):\n",
    "    def __init__(self, num_hid=64, maxlen=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid,trainable=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.conv3(x)\n",
    "\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.self_att = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.self_dropout = layers.Dropout(0.5)\n",
    "        self.enc_dropout = layers.Dropout(0.1)\n",
    "        self.ffn_dropout = layers.Dropout(0.1)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "205044f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    num_hid=128,\n",
    "    num_head=2,\n",
    "    num_feed_forward=256,\n",
    "    target_maxlen=max_target_len,\n",
    "    num_layers_enc=2,\n",
    "    num_layers_dec=1,\n",
    "    #num_classes=len(vectorizer.get_vocabulary()) # 75 # 48 # 67 # 108,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dadfdcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embeddings Shape: (1, 100, 1, 64)\n",
      "Speech Feature Embeddings Shape: (1, 13, 64)\n",
      "Encoder Output Shape: (1, 13, 64)\n",
      "Decoder Output Shape: (1, 13, 64)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 100\n",
    "num_hid = 64\n",
    "\n",
    "# Create an instance of the TokenEmbedding layer\n",
    "token_embedding_layer = TokenEmbedding(num_vocab=1000, maxlen=maxlen, num_hid=num_hid)\n",
    "\n",
    "# Create an instance of the SpeechFeatureEmbedding layer\n",
    "speech_feature_embedding_layer = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=maxlen)\n",
    "\n",
    "# Create an instance of the TransformerEncoder layer\n",
    "transformer_encoder_layer = TransformerEncoder(embed_dim=num_hid, num_heads=2, feed_forward_dim=256, rate=0.1)\n",
    "\n",
    "# Create an instance of the TransformerDecoder layer\n",
    "transformer_decoder_layer = TransformerDecoder(embed_dim=num_hid, num_heads=2, feed_forward_dim=256, dropout_rate=0.1)\n",
    "\n",
    "# Define a sample input tensor\n",
    "input_tensor = tf.random.uniform((1, maxlen, 1), dtype=tf.float32)  # Batch size of 1, 1 channel\n",
    "\n",
    "# Pass the input tensor through each layer to calculate the output shapes\n",
    "token_embeddings = token_embedding_layer(input_tensor)\n",
    "speech_embeddings = speech_feature_embedding_layer(input_tensor)\n",
    "encoder_output = transformer_encoder_layer(speech_embeddings, training=True)\n",
    "decoder_output = transformer_decoder_layer(encoder_output, training=True)\n",
    "\n",
    "# Print the shapes of the intermediate outputs\n",
    "print(\"Token Embeddings Shape:\", token_embeddings.shape)\n",
    "print(\"Speech Feature Embeddings Shape:\", speech_embeddings.shape)\n",
    "print(\"Encoder Output Shape:\", encoder_output.shape)\n",
    "print(\"Decoder Output Shape:\", decoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8353f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Your list of values (replace with your actual list)\n",
    "wer_values = [1,0.92665667,0.83615385,0.76671429,0.74333333,0.6775,\n",
    " 0.64705882,0.61711111,0.57724737,0.54,0.53380952,0.59,\n",
    " 0.47517087,0.46833633,0.4354,0.42507692,0.41740741,0.39285714,\n",
    " 0.38531034,0.36866667,0.36483871,0.35375,0.37363333,0.33362941,\n",
    " 0.31428571, 0.30755556,0.3172973,0.29347368,0.28705128,0.2737,\n",
    " 0.26527268,0.26090476 ,0.25681395,0.25105,0.24644744,0.23413343,\n",
    " 0.23904255,0.22716667,0.2274798,0.21967,0.21568627,0.21153846,\n",
    " 0.21754617,0.2033077,0.2008,0.19742557,0.19398746,0.18767517,\n",
    " 0.18548068,0.18373383,0.17952787,0.17711735,0.17160317,0.174385,\n",
    " 0.16823087,0.16566867,0.1631761,0.16078471,0.16082029,0.15684286,\n",
    " 0.15392758,0.15477278,0.15088473,0.14764365,0.14766867,0.14533284,\n",
    " 0.14382624,0.14143564,0.13174311,0.13686,0.13280357,0.13374534,\n",
    " 0.13313012,0.13995238,0.12881176,0.12810658,0.12593618,0.124905,\n",
    " 0.12339451,0.12182712,0.12117412,0.12917522,0.11628957,0.11472328,\n",
    " 0.11538647,0.1159833,0.11335206,0.1127949,0.11371311,0.110356,\n",
    " 0.10941089,0.10824314,0.10639512,0.10746423,0.0928619,0.10378158,\n",
    " 0.10230374,0.10025585,0.10091843,0.0942]\n",
    "# Define the file name for the JSON file\n",
    "json_file_name = 'wer_values.json'\n",
    "\n",
    "# Save the list to a JSON file\n",
    "with open(json_file_name, 'w') as json_file:\n",
    "    json.dump(wer_values, json_file)\n",
    "\n",
    "print(f'WER values saved to {json_file_name}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
